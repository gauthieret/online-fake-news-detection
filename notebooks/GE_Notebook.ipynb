{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# fake_csv = \"../online-fake-news-detection/data/Fake.csv\"\n",
    "# true_csv = \"../online-fake-news-detection/data/True.csv\"\n",
    "# fake_df = pd.read_csv(fake_csv)\n",
    "# true_df = pd.read_csv(true_csv)\n",
    "# true_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trafilatura\n",
    "downloaded = trafilatura.fetch_url('https://edition.cnn.com/europe/live-news/russia-ukraine-war-news-11-29-22/index.html')\n",
    "trafilatura.extract(downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NATO foreign ministers said Tuesday in a joint...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title_texte\n",
       "0  NATO foreign ministers said Tuesday in a joint..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trafilatura import extract, fetch_url\n",
    "downloaded = fetch_url('https://edition.cnn.com/europe/live-news/russia-ukraine-war-news-11-29-22/index.html')\n",
    "provided_article = pd.DataFrame({'title_texte': [extract(downloaded)]})\n",
    "provided_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GH Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>True</td>\n",
       "      <td>There are a larger number of shark attacks in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>True</td>\n",
       "      <td>Democrats have now become the party of the [At...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>True</td>\n",
       "      <td>Says an alternative to Social Security that op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>False</td>\n",
       "      <td>On lifting the U.S. Cuban embargo and allowing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10239</th>\n",
       "      <td>False</td>\n",
       "      <td>The Department of Veterans Affairs has a manua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10240 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               news\n",
       "0      False  Says the Annies List political group supports ...\n",
       "1       True  When did the decline of coal start? It started...\n",
       "2       True  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3      False  Health care reform legislation is likely to ma...\n",
       "4       True  The economic turnaround started at the end of ...\n",
       "...      ...                                                ...\n",
       "10235   True  There are a larger number of shark attacks in ...\n",
       "10236   True  Democrats have now become the party of the [At...\n",
       "10237   True  Says an alternative to Social Security that op...\n",
       "10238  False  On lifting the U.S. Cuban embargo and allowing...\n",
       "10239  False  The Department of Veterans Affairs has a manua...\n",
       "\n",
       "[10240 rows x 2 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "new_csv = \"../online-fake-news-detection/data/fakenews.csv\"\n",
    "news_df = pd.read_csv(new_csv)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_df['True'] = True\n",
    "# fake_df['True'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = news_df.rename(columns={'label':'True', 'news' : 'title_text'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles_df = pd.merge(true_df,fake_df, 'outer')\n",
    "#articles_df['title_text'] = articles_df['title'] + articles_df['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    True                                         title_text\n",
       "0  False  Says the Annies List political group supports ...\n",
       "1   True  When did the decline of coal start? It started...\n",
       "2   True  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3  False  Health care reform legislation is likely to ma...\n",
       "4   True  The economic turnaround started at the end of ..."
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10240 entries, 0 to 10239\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   True        10240 non-null  bool  \n",
      " 1   title_text  10240 non-null  object\n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 90.1+ KB\n"
     ]
    }
   ],
   "source": [
    "articles_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import unidecode\n",
    "\n",
    "articles_df\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    \n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase \n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers\n",
    "    \n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "\n",
    "    unaccented_string = unidecode.unidecode(sentence) # remove accents\n",
    "\n",
    "    tokenized_sentence = word_tokenize(unaccented_string) ## tokenize \n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "\n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "    w for w in tokenized_sentence if not w in stop_words\n",
    "            ]\n",
    "\n",
    "    lemmatized = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"v\") \n",
    "    for word in tokenized_sentence_cleaned\n",
    "    ]\n",
    "    \n",
    "    cleaned_sentence = ' '.join(word for word in lemmatized)\n",
    "\n",
    "    \n",
    "    return cleaned_sentence\n",
    "\n",
    "articles_df['cleaned_title_text'] = articles_df['title_text'].apply(preprocessing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = 'True'\n",
    "feature = articles_df['cleaned_title_text']\n",
    "\n",
    "def X_y(df, TARGET_COLUMN):\n",
    "    X = df.drop([TARGET_COLUMN], axis=1)\n",
    "    y = df[TARGET_COLUMN]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def split_data(X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\\\n",
    "        test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X, y = X_y(articles_df, target)\n",
    "X_train, X_test, y_train, y_test = split_data(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_text</th>\n",
       "      <th>cleaned_title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>Wall Street megabanks that received bailouts i...</td>\n",
       "      <td>wall street megabanks receive bailouts get tax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>Weve got more revenue than we ever have.</td>\n",
       "      <td>weve get revenue ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>North Dakotas economy is reeling.</td>\n",
       "      <td>north dakotas economy reel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>Bill OBriens Tea Party legislature tried to re...</td>\n",
       "      <td>bill obriens tea party legislature try repeal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>Says Connie Macks Penny Plan would cut over $2...</td>\n",
       "      <td>say connie macks penny plan would cut billion ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_text  \\\n",
       "4919  Wall Street megabanks that received bailouts i...   \n",
       "1332           Weve got more revenue than we ever have.   \n",
       "8207                  North Dakotas economy is reeling.   \n",
       "3485  Bill OBriens Tea Party legislature tried to re...   \n",
       "3688  Says Connie Macks Penny Plan would cut over $2...   \n",
       "\n",
       "                                     cleaned_title_text  \n",
       "4919  wall street megabanks receive bailouts get tax...  \n",
       "1332                              weve get revenue ever  \n",
       "8207                         north dakotas economy reel  \n",
       "3485  bill obriens tea party legislature try repeal ...  \n",
       "3688  say connie macks penny plan would cut billion ...  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "X_train_cleaned_title_text = X_train['cleaned_title_text']\n",
    "X_test_cleaned_title_text = X_test['cleaned_title_text']\n",
    "\n",
    "def train_vect(X: np.ndarray):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.7)\n",
    "    tfidf_fitted = tfidf_vectorizer.fit(X)\n",
    "    \n",
    "    return tfidf_fitted\n",
    "\n",
    "\n",
    "def transform_vect(X: np.ndarray, tfdidf_fitted):\n",
    "    tfidf_transformed = tfdidf_fitted.transform(X)\n",
    "\n",
    "    return tfidf_transformed\n",
    "\n",
    "\n",
    "tfdidf_fitted = train_vect(X_train_cleaned_title_text)\n",
    "X_train_vectorized = transform_vect(X_train_cleaned_title_text, tfdidf_fitted)\n",
    "X_test_vectorized = transform_vect(X_test_cleaned_title_text, tfdidf_fitted)\n",
    "\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_df=0.7)\n",
    "# X_train_vectorized = tfidf_vectorizer.fit_transform(X_train_cleaned_title_text)\n",
    "# X_test_vectorized = tfidf_vectorizer.transform(X_test_cleaned_title_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3072x8518 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 29415 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized\n",
    "X_test_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate : Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "# Cross-validation\n",
    "cv_results = cross_validate(PassiveAggressiveClassifier(max_iter=50, \n",
    "                                                        n_jobs=-1, \n",
    "                                                        random_state=42, \n",
    "                                                        fit_intercept=False, \n",
    "                                                        early_stopping=True,\n",
    "                                                        validation_fraction=0.2, \n",
    "                                                        n_iter_no_change=5),\n",
    "                             X_train_vectorized, y_train, cv=5, scoring=[\"accuracy\"])\n",
    "average_accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "np.round(average_accuracy,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01806879, 0.01921201, 0.01510382, 0.01245284, 0.0155642 ]),\n",
       " 'score_time': array([0.00065207, 0.00085473, 0.00082111, 0.00055408, 0.00058007]),\n",
       " 'test_accuracy': array([0.58647141, 0.5460251 , 0.57810321, 0.57013259, 0.54291696])}"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If Validated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "# def pa_classifier_fit(tfidf_train, y_train):\n",
    "\n",
    "#     pac=PassiveAggressiveClassifier(max_iter=50, n_jobs=-1, random_state=0, fit_intercept=False, early_stopping=True,\n",
    "#                                 validation_fraction=0.2, n_iter_no_change=5)\n",
    "#     pac.fit(tfidf_train,y_train)\n",
    "\n",
    "#     return pac\n",
    "\n",
    "# pac = pa_classifier_fit(X_train_vectorized, y_train)\n",
    "# pac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def y_pred(pac, tfidf_test):\n",
    "\n",
    "#     y_pred = pac.predict(tfidf_test)\n",
    "\n",
    "#     return y_pred\n",
    "# y_predicted = y_pred(pac,X_test_vectorized)\n",
    "# y_predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('online-fake-news-detection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0b61e090d0ce072d1ebe263efbdfced32abe751f0ff09162c12e4f661763592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
